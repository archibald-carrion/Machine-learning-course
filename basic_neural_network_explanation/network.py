import numpy as np
from datetime import datetime

# Define the sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def create_neural_network_log():
    # Create log content
    log_content = []
    
    # Header
    log_content.append("=" * 80)
    log_content.append("ğŸ§  NEURAL NETWORK FORWARD PASS CALCULATION LOG")
    log_content.append("=" * 80)
    log_content.append(f"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    log_content.append(f"ğŸ—ï¸  Architecture: 4 Input â†’ 3 Hidden â†’ 2 Output")
    log_content.append(f"âš¡ Activation Function: Sigmoid")
    log_content.append("")
    
    # Input data
    x = np.array([2, 3, -1, 2])
    W1 = np.array([
        [2, 3, 0, 1],
        [4, 3, 2, 0],
        [1, 1, 1, 2]
    ])
    W2 = np.array([
        [1, 7, 1],
        [7, 1, 4]
    ])
    b = np.array([-6, -2])
    
    # Input section
    log_content.append("ğŸ“Š INPUT DATA")
    log_content.append("-" * 40)
    log_content.append(f"ğŸ”¢ Input Vector x: {x.tolist()}")
    log_content.append("")
    log_content.append("ğŸ”— Weight Matrix W1 (Input â†’ Hidden):")
    for i, row in enumerate(W1):
        log_content.append(f"   Row {i+1}: {row.tolist()}")
    log_content.append("")
    log_content.append("ğŸ”— Weight Matrix W2 (Hidden â†’ Output):")
    for i, row in enumerate(W2):
        log_content.append(f"   Row {i+1}: {row.tolist()}")
    log_content.append("")
    log_content.append(f"âš–ï¸  Bias Vector b: {b.tolist()}")
    log_content.append("")
    
    # Forward pass calculations
    log_content.append("ğŸš€ FORWARD PASS COMPUTATION")
    log_content.append("-" * 40)
    
    # Layer 1: Input to Hidden
    log_content.append("ğŸ“ STEP 1: Input â†’ Hidden Layer")
    z1 = W1 @ x
    log_content.append(f"   ğŸ§® Pre-activation z1 = W1 Ã— x")
    for i in range(3):
        calculation_parts = []
        for j in range(4):
            calculation_parts.append(f"{W1[i,j]}Ã—{x[j]}")
        calculation = " + ".join(calculation_parts)
        log_content.append(f"   z1[{i+1}] = {calculation} = {z1[i]}")
    log_content.append("")
    
    a1 = sigmoid(z1)
    log_content.append("   âš¡ Applying Sigmoid Activation:")
    for i in range(3):
        log_content.append(f"   a1[{i+1}] = Ïƒ({z1[i]}) = {a1[i]:.6f}")
    log_content.append("")
    
    # Layer 2: Hidden to Output
    log_content.append("ğŸ“ STEP 2: Hidden â†’ Output Layer")
    z2_no_bias = W2 @ a1
    z2 = z2_no_bias + b
    log_content.append(f"   ğŸ§® Pre-activation z2 = W2 Ã— a1 + b")
    for i in range(2):
        calculation_parts = []
        for j in range(3):
            calculation_parts.append(f"{W2[i,j]}Ã—{a1[j]:.6f}")
        calculation = " + ".join(calculation_parts)
        log_content.append(f"   z2[{i+1}] = {calculation} + {b[i]} = {z2[i]:.6f}")
    log_content.append("")
    
    a2 = sigmoid(z2)
    log_content.append("   âš¡ Applying Sigmoid Activation:")
    for i in range(2):
        log_content.append(f"   a2[{i+1}] = Ïƒ({z2[i]:.6f}) = {a2[i]:.6f}")
    log_content.append("")
    
    # Final results
    log_content.append("ğŸ¯ FINAL RESULTS")
    log_content.append("-" * 40)
    log_content.append(f"ğŸ”¹ Hidden Layer Output: {[f'{val:.6f}' for val in a1]}")
    log_content.append(f"ğŸ”¹ Network Final Output: {[f'{val:.6f}' for val in a2]}")
    log_content.append("")
    
    # Mathematical formulas
    log_content.append("ğŸ“ MATHEMATICAL FORMULAS REFERENCE")
    log_content.append("-" * 40)
    log_content.append("ğŸ”¸ Linear Transformation: z = W Ã— a + b")
    log_content.append("ğŸ”¸ Sigmoid Activation: Ïƒ(x) = 1 / (1 + e^(-x))")
    log_content.append("ğŸ”¸ Forward Propagation:")
    log_content.append("   â€¢ Hidden Layer: a1 = Ïƒ(W1 Ã— x)")
    log_content.append("   â€¢ Output Layer: a2 = Ïƒ(W2 Ã— a1 + b)")
    log_content.append("")
    
    # Network summary
    log_content.append("ğŸ“‹ NETWORK SUMMARY")
    log_content.append("-" * 40)
    log_content.append(f"ğŸ“Œ Total Parameters: {W1.size + W2.size + b.size}")
    log_content.append(f"ğŸ“Œ W1 Parameters: {W1.size} (3Ã—4)")
    log_content.append(f"ğŸ“Œ W2 Parameters: {W2.size} (2Ã—3)")
    log_content.append(f"ğŸ“Œ Bias Parameters: {b.size}")
    log_content.append(f"ğŸ“Œ Network Depth: 3 layers")
    log_content.append("")
    
    # Footer
    log_content.append("=" * 80)
    log_content.append("âœ… NEURAL NETWORK COMPUTATION COMPLETED SUCCESSFULLY")
    log_content.append("=" * 80)
    
    return "\n".join(log_content)

# Generate and save the log
if __name__ == "__main__":
    log_text = create_neural_network_log()
    # Write to file (no timestamped version)
    with open('neural_network_log.txt', 'w', encoding='utf-8') as f:
        f.write(log_text)